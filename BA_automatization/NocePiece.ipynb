{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65737513-f6f3-4eda-bb6e-d93ff3bffa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pykeen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.constants import PYKEEN_CHECKPOINTS\n",
    "import torch\n",
    "import torch.nn\n",
    "import argparse\n",
    "from pykeen.regularizers import Regularizer, regularizer_resolver\n",
    "from pykeen.utils import resolve_device\n",
    "\n",
    "#import all models and parameter\n",
    "from pykeen.models  import ConvE, TransE, ComplEx, MuRE, RotatE, TuckER, DistMult, RESCAL, NodePiece\n",
    "from pykeen.training import LCWATrainingLoop, SLCWATrainingLoop\n",
    "from pykeen.losses import BCEWithLogitsLoss, SoftplusLoss, NSSALoss, SoftMarginRankingLoss, PairwiseLogisticLoss\n",
    "\n",
    "# testing:\n",
    "from pykeen.datasets import Nations\n",
    "from pykeen.models import NodePiece\n",
    "from pykeen.datasets import FB15k237, Nations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d5d2d8-d9e2-4012-810a-2b115e744712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OMOP_21600001' '0' 'OMOP_21600509']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're trying to map triples with 30 entities and 0 relations that are not in the training set. These triples will be excluded from the mapping.\n",
      "In total 28 from 20466 triples were filtered out\n",
      "No random seed is specified. This may lead to non-reproducible results.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/14.5k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sc-projects/sc-proj-ukb-cvd/environments/gnn/lib/python3.9/site-packages/pykeen/nn/representation.py:369: UserWarning: Directly use Embedding.max_id instead of num_embeddings.\n",
      "  warnings.warn(f\"Directly use {self.__class__.__name__}.max_id instead of num_embeddings.\")\n",
      "/sc-projects/sc-proj-ukb-cvd/environments/gnn/lib/python3.9/site-packages/pykeen/nn/representation.py:375: UserWarning: Directly use Embedding.shape instead of num_embeddings.\n",
      "  warnings.warn(f\"Directly use {self.__class__.__name__}.shape instead of num_embeddings.\")\n"
     ]
    }
   ],
   "source": [
    "# Testing NodePiece in for further experimenting\n",
    "triple_path = '/sc-projects/sc-proj-ukb-cvd/data/2_datasets_pre/220208_graphembeddings/triples/triple_list_graph_full_v3.feather'\n",
    "\n",
    "# inverses are necessary for the current version of NodePiece!\n",
    "dataset = FB15k237(create_inverse_triples=True)\n",
    "Nations_dataset = Nations(create_inverse_triples=True)\n",
    "owndata = pd.read_feather(triple_path).to_numpy()\n",
    "print(owndata[0])\n",
    "owndataset = [owndata[i] for i in range(1000)]\n",
    "owndataset = np.asarray(owndataset)\n",
    "own_tf = TriplesFactory.from_labeled_triples(owndataset, create_inverse_triples=True)\n",
    "\n",
    "\n",
    "# -> https://pykeen.readthedocs.io/en/stable/reference/nn/node_piece.html\n",
    "#Next, we’ll use a combination of tokenizers (pykeen.nn.node_piece.AnchorTokenizer and pykeen.nn.node_piece.RelationTokenizer) \n",
    "# to replicate the full NodePiece tokenization with anchors and relational context. It’s as easy as sending a list of tokenizers to tokenizers and sending a list of arguments to num_tokens\n",
    "\n",
    "# SIMPLE\n",
    "simple_model = NodePiece(\n",
    "    triples_factory=dataset.training,\n",
    "    tokenizers=[\"AnchorTokenizer\", \"RelationTokenizer\"],\n",
    "    num_tokens=[8, 10], # default selection=32\n",
    "    embedding_dim=64,\n",
    ")\n",
    "# now we instantiateted AnchorTokenizer with 20 anchors per node and Relation Tokenizer with 12 relations per node.\n",
    "#NOTE: we found there is a saturation point around 20 anchors per node even in million-node graphs. \"https://towardsdatascience.com/nodepiece-tokenizing-knowledge-graphs-6dd2b91847aa\"\n",
    "# 1. AnchorTokenizer has two fiels: \"selection\":controls how we sample anchors from the graph (32 anchors by default); \"searcher\":controls how we tokenize nodes using selected anchors (CSGraphAnchorSearcher by default)\n",
    "# 2. -> uses scipy.sparse to compute shortest paths form all nodes in the graph to all anchors -> expensive!! for tokenaziation\n",
    "# 3. ! Larger Graphs:use BFS from ScipySparseAnchorSearcher, it applies BFS by iteratively expanding node neighborhood until it finds a desired number of anchors ->> saves compute time\n",
    "# 4. to replicate the full NodePiece tokenization with k anchors and m relational context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4cf95-b0dd-441a-830b-7ccf11ae3443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202 700380\n"
     ]
    }
   ],
   "source": [
    "# test out the triples factory\n",
    "test_tf = TriplesFactory.from_labeled_triples(owndata, create_inverse_triples=False)\n",
    "print(test_tf.num_relations, test_tf.num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09b27b-053e-4340-945a-d51195bf9fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf23936014e40408f48b09b26906402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/4 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/13 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/13 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/13 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/13 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SIMPLE 2\n",
    "\n",
    "# try own pipeline with simple model and Nations dataset:\n",
    "\n",
    "# Pick an optimizer from Torch\n",
    "from torch.optim import Adam\n",
    "optimizer = Adam(params=model2.get_grad_params())\n",
    "\n",
    "# Pick a training approach that was imported !! contains the losses, choose between SLCWATrainingLoop and LCWATrainingLoop\n",
    "training_loop = SLCWATrainingLoop(    \n",
    "    model=model2,\n",
    "    triples_factory=Nations_dataset.training,\n",
    "    optimizer=optimizer,\n",
    "    automatic_memory_optimization=True, \n",
    ")\n",
    "\n",
    "simple_losses = training_loop.train(\n",
    "    \n",
    "    triples_factory=Nations_dataset.training,\n",
    "    num_epochs=4,\n",
    "    batch_size=None, #256, # if None -> automatic search for the best and greatest\n",
    "    checkpoint_name= \"First_7NodePiece\", # for example TransE_t2.pt\n",
    "    checkpoint_frequency=0,\n",
    "    checkpoint_directory='/sc-scratch/sc-scratch-ukb-cvd/checkpoints_pykeen_leonard', # new checkpoint dir bc of massive storage needs\n",
    "    \n",
    "    sub_batch_size=None, # not for SLCWA and not supported bc of batch normalization!!\n",
    "    slice_size=None, # not for SLCWA\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c2a22481-6516-4221-8be1-0f4a5f8034ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Embedding(\n",
      "  (_embeddings): Embedding(15, 64)\n",
      ") <class 'pykeen.nn.node_piece.representations.TokenizationRepresentation'>\n",
      "vocab Type: <class 'pykeen.nn.representation.Embedding'>\n",
      "<class 'pykeen.nn.node_piece.representations.NodePieceRepresentation'> aggreg: <built-in method mean of type object at 0x7fd2e0e14ee0> token_rep:  ModuleList(\n",
      "  (0): TokenizationRepresentation(\n",
      "    max_id=14,\n",
      "    num_tokens=8,\n",
      "    vocabulary_size=15,\n",
      "    (vocabulary): Embedding(\n",
      "      (_embeddings): Embedding(15, 64)\n",
      "    )\n",
      "  )\n",
      "  (1): TokenizationRepresentation(\n",
      "    max_id=14,\n",
      "    num_tokens=10,\n",
      "    vocabulary_size=111,\n",
      "    (vocabulary): Embedding(\n",
      "      (_embeddings): Embedding(111, 64)\n",
      "    )\n",
      "  )\n",
      ") shape:  (64,)\n",
      "######: tensor([[ 0.2257, -0.4834,  0.1831, -0.2359,  0.2199,  0.3202, -0.1954, -0.3852,\n",
      "         -0.2191,  0.1879,  0.3445, -0.1156, -0.0418,  0.0073,  0.0801,  0.3840,\n",
      "          0.0636,  0.1547,  0.3005,  0.0387,  0.0819,  0.2374,  0.4449,  0.2294,\n",
      "         -0.2591, -0.1377, -0.0305, -0.0385,  0.1236,  0.2970,  0.2533,  0.1774,\n",
      "         -0.0185, -0.0622,  0.1445, -0.0563,  0.3080,  0.3397,  0.0435,  0.1625,\n",
      "          0.1447,  0.3666, -0.1592,  0.3819,  0.3450, -0.2677,  0.2481, -0.2108,\n",
      "         -0.0115, -0.0204,  0.3497,  0.2394,  0.0621,  0.2285, -0.1230,  0.2002,\n",
      "         -0.0346, -0.3437, -0.0230, -0.0695, -0.0015,  0.4168, -0.2641, -0.1705]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "<class 'pykeen.nn.representation.SubsetRepresentation'> SubsetRepresentation(\n",
      "  (base): Embedding(\n",
      "    (_embeddings): Embedding(111, 64)\n",
      "  )\n",
      ")\n",
      "{'brazil': 0, 'burma': 1, 'china': 2, 'cuba': 3, 'egypt': 4, 'india': 5, 'indonesia': 6, 'israel': 7, 'jordan': 8, 'netherlands': 9, 'poland': 10, 'uk': 11, 'usa': 12, 'ussr': 13} \n",
      "\n",
      "{'accusation': 0, 'aidenemy': 1, 'attackembassy': 2, 'blockpositionindex': 3, 'booktranslations': 4, 'boycottembargo': 5, 'commonbloc0': 6, 'commonbloc1': 7, 'commonbloc2': 8, 'conferences': 9, 'dependent': 10, 'duration': 11, 'economicaid': 12, 'eemigrants': 13, 'embassy': 14, 'emigrants3': 15, 'expeldiplomats': 16, 'exportbooks': 17, 'exports3': 18, 'independence': 19, 'intergovorgs': 20, 'intergovorgs3': 21, 'lostterritory': 22, 'militaryactions': 23, 'militaryalliance': 24, 'negativebehavior': 25, 'negativecomm': 26, 'ngo': 27, 'ngoorgs3': 28, 'nonviolentbehavior': 29, 'officialvisits': 30, 'pprotests': 31, 'relbooktranslations': 32, 'reldiplomacy': 33, 'releconomicaid': 34, 'relemigrants': 35, 'relexportbooks': 36, 'relexports': 37, 'relintergovorgs': 38, 'relngo': 39, 'relstudents': 40, 'reltourism': 41, 'reltreaties': 42, 'severdiplomatic': 43, 'students': 44, 'timesinceally': 45, 'timesincewar': 46, 'tourism': 47, 'tourism3': 48, 'treaties': 49, 'unoffialacts': 50, 'unweightedunvote': 51, 'violentactions': 52, 'warning': 53, 'weightedunvote': 54}\n",
      "tensor([ 0.3483, -0.3843, -0.1275, -0.2272, -0.2090, -0.1254,  0.0267, -0.0952,\n",
      "         0.0008, -0.0132,  0.4311, -0.1789, -0.4563,  0.1212,  0.1334, -0.0847,\n",
      "        -0.0947, -0.0797, -0.1304, -0.2108, -0.1608,  0.2378,  0.2582,  0.1040,\n",
      "         0.1500,  0.0477, -0.3466,  0.0213,  0.4998, -0.2771, -0.0398,  0.5594,\n",
      "        -0.3466, -0.0982, -0.1619,  0.0441,  0.2769,  0.2054, -0.2576,  0.4228,\n",
      "        -0.3615, -0.0657,  0.0968,  0.0120,  0.0723,  0.4491, -0.3157, -0.4686,\n",
      "         0.0820, -0.0312, -0.0821,  0.0978,  0.0331, -0.0513, -0.0261, -0.0925,\n",
      "        -0.0206, -0.1138, -0.4362, -0.2075,  0.1791,  0.1086, -0.2614, -0.0516],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "<class 'pykeen.nn.node_piece.representations.NodePieceRepresentation'> NodePieceRepresentation(\n",
      "  aggregation=mean, \n",
      "  (token_representations): ModuleList(\n",
      "    (0): TokenizationRepresentation(\n",
      "      max_id=14,\n",
      "      num_tokens=8,\n",
      "      vocabulary_size=11,\n",
      "      (vocabulary): Embedding(\n",
      "        (_embeddings): Embedding(11, 64)\n",
      "      )\n",
      "    )\n",
      "    (1): TokenizationRepresentation(\n",
      "      max_id=14,\n",
      "      num_tokens=10,\n",
      "      vocabulary_size=111,\n",
      "      (vocabulary): Embedding(\n",
      "        (_embeddings): Embedding(111, 64)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "######: tensor([[ 0.2257, -0.4834,  0.1831, -0.2359,  0.2199,  0.3202, -0.1954, -0.3852,\n",
      "         -0.2191,  0.1879,  0.3445, -0.1156, -0.0418,  0.0073,  0.0801,  0.3840,\n",
      "          0.0636,  0.1547,  0.3005,  0.0387,  0.0819,  0.2374,  0.4449,  0.2294,\n",
      "         -0.2591, -0.1377, -0.0305, -0.0385,  0.1236,  0.2970,  0.2533,  0.1774,\n",
      "         -0.0185, -0.0622,  0.1445, -0.0563,  0.3080,  0.3397,  0.0435,  0.1625,\n",
      "          0.1447,  0.3666, -0.1592,  0.3819,  0.3450, -0.2677,  0.2481, -0.2108,\n",
      "         -0.0115, -0.0204,  0.3497,  0.2394,  0.0621,  0.2285, -0.1230,  0.2002,\n",
      "         -0.0346, -0.3437, -0.0230, -0.0695, -0.0015,  0.4168, -0.2641, -0.1705]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "    nodes                                         embeddings\n",
      "0  brazil  [0.2582999, -0.37510505, -0.29952687, -0.51248...\n",
      "1   burma  [-0.062382527, -0.2281509, -0.38129398, 0.1086...\n",
      "2   china  [0.34825706, -0.38426244, -0.12749049, -0.2271...\n",
      "3    cuba  [0.11077488, -0.09046424, -0.2701691, -0.33044...\n",
      "4   egypt  [-0.27346054, -0.34025225, 0.07646023, -0.1074...\n"
     ]
    }
   ],
   "source": [
    "# SIMPLE 3\n",
    "# TRY to accses embeddings out of simple_model nations dataset\n",
    "#entit_rep=simple_model.entity_representations[0]\n",
    "print(entit_rep.token_representations[0].vocabulary_size, entit_rep.token_representations[0].vocabulary,type(entit_rep.token_representations[1]))\n",
    "vocab = entit_rep.token_representations[0].vocabulary\n",
    "print('vocab Type:',type(vocab)) # the token representations (15x64)\n",
    "# THATS IT !!\n",
    "print(type(entit_rep),'aggreg:',entit_rep.aggregation, 'token_rep: ',entit_rep.token_representations ,'shape: ', entit_rep.shape)\n",
    "print('######:',entit_rep([13]))\n",
    "######################\n",
    "# relation representation\n",
    "relat_rep=simple_model.relation_representations[0]\n",
    "print(type(relat_rep), relat_rep)\n",
    "\n",
    "# check out IDS of tripleFactory!\n",
    "entity_dict=Nations_dataset.training.entity_to_id\n",
    "relation_dict=Nations_dataset.training.relation_to_id\n",
    "print(entity_dict,'\\n')\n",
    "print(relation_dict)\n",
    "print(entit_rep(entity_dict['china']) )\n",
    "\n",
    "# check difference to model2\n",
    "entit2_rep=model2.entity_representations[0]\n",
    "print(type(entit2_rep), entit2_rep)\n",
    "print('######:',entit_rep([13]))\n",
    "\n",
    "\n",
    "entity_id_dict = Nations_dataset.training.entity_to_id\n",
    "entity_ids_as_tensors = torch.as_tensor([int(v) for v in entity_id_dict.values()], dtype=torch.long)\n",
    "entity_embeddings =entit_rep(indices=entity_ids_as_tensors).detach().numpy()\n",
    "\n",
    "df_dict = pd.DataFrame(dict(nodes= entity_id_dict.keys(), embeddings=list(entity_embeddings)))\n",
    "print(df_dict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e37f32-8f1c-4c6e-b2db-1011613f5057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. This may lead to non-reproducible results.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/14.5k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for 15k nodes better use 100 anchors, selected with the top degree-strategy by sending tokenizer_kwargs list:\n",
    "model2 = NodePiece(\n",
    "    triples_factory=dataset.training, # Nations_dataset.training\n",
    "    tokenizers=[\"AnchorTokenizer\", \"RelationTokenizer\"],\n",
    "    num_tokens=[20, 12], # fitst Anchor, then Relation  #8,10\n",
    "    tokenizers_kwargs=[\n",
    "        dict(\n",
    "            selection=\"Degree\", # node selecting strategy\n",
    "            selection_kwargs=dict(\n",
    "                num_anchors=500, #10\n",
    "            ),\n",
    "            searcher=\"CSGraph\",\n",
    "        ),\n",
    "        dict(),  # empty dict for the RelationTokenizer - it doesn't need any kwargs\n",
    "    ],\n",
    "    embedding_dim=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c49040-4288-4e6e-92c8-08acabc91c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. This may lead to non-reproducible results.\n",
      "9/14505 (0.06%) do not have any anchor.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/14.5k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'tokenizers_kwargs=[\\n        dict(\\n            selection=\"MixtureAnchorSelection\",    #!!\\n            selection_kwargs=dict(\\n                selections=[\"degree\", \"pagerank\", \"random\"], #!!  last \"random\" is avaiable also\\n                ratios=[0.4, 0.4, 0.2],                 #!!\\n                num_anchors=500,\\n            ),\\n            searcher=\"ScipySparse\",\\n        ),\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s create a model with 500 top-pagerank anchors selected with the BFS strategy - we’ll just modify the selection and searcher args:\n",
    "\n",
    "big_Dat_model= NodePiece(\n",
    "    triples_factory=dataset.training,\n",
    "    tokenizers=[\"AnchorTokenizer\", \"RelationTokenizer\"],\n",
    "    num_tokens=[20, 12],\n",
    "    tokenizers_kwargs=[\n",
    "        dict(\n",
    "            selection=\"PageRank\",\n",
    "            selection_kwargs=dict(\n",
    "                num_anchors=500,\n",
    "            ),\n",
    "            searcher=\"ScipySparse\", #breadth-first search!\n",
    "        ),\n",
    "        dict(),  # empty dict for the RelationTokenizer - it doesn't need any kwargs\n",
    "    ],\n",
    "    embedding_dim=64,\n",
    ")\n",
    "\n",
    "class DeepSet(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, dim=-2):\n",
    "        x = self.encoder(x).mean(dim)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "# if you want to use several anchor selection strategies sequentially to select more diverse anchors use the \"pykeen.nn.node_piece.MixtureAnchorSelection \" class:\n",
    "# from the NodePiece Paper:\n",
    "\"\"\"tokenizers_kwargs=[\n",
    "        dict(\n",
    "            selection=\"MixtureAnchorSelection\",    #!!\n",
    "            selection_kwargs=dict(\n",
    "                selections=[\"degree\", \"pagerank\", \"random\"], #!!  last \"random\" is avaiable also\n",
    "                ratios=[0.4, 0.4, 0.2],                 #!!\n",
    "                num_anchors=500,\n",
    "            ),\n",
    "            searcher=\"ScipySparse\",\n",
    "        ),\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d04b89-86a1-48a1-95cf-41be2db3e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. This may lead to non-reproducible results.\n",
      "9/14505 (0.06%) do not have any anchor.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling:   0%|          | 0.00/14.5k [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b55f5988ca4d0285d6d91c0da8f299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/4 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f9c44d47a447728e0f4a15e243b493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/2126 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3674753/1723711933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m losses = training_loop.train(\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mtriples_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sc-projects/sc-proj-ukb-cvd/environments/gnn/lib/python3.9/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;31m# send model to device before going into the internal training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_preferred_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_ambiguity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             result = self._train(\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sc-projects/sc-proj-ukb-cvd/environments/gnn/lib/python3.9/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                         \u001b[0;31m# forward pass call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                         batch_loss = self._forward_pass(\n\u001b[0m\u001b[1;32m    605\u001b[0m                             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sc-projects/sc-proj-ukb-cvd/environments/gnn/lib/python3.9/site-packages/pykeen/training/training_loop.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m         \u001b[0mcurrent_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sc-projects/sc-proj-ukb-cvd/environments/gnn/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sc-projects/sc-proj-ukb-cvd/environments/gnn/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build nodepiece into the pipeline:\n",
    "\n",
    "\n",
    "\n",
    "own_NodePiece=NodePiece(\n",
    "    triples_factory=dataset.training,\n",
    "    tokenizers=[\"AnchorTokenizer\", \"RelationTokenizer\"],\n",
    "        num_tokens=[20, 12],\n",
    "        tokenizers_kwargs=[\n",
    "            dict(\n",
    "                selection=\"MixtureAnchorSelection\",\n",
    "                selection_kwargs=dict(\n",
    "                    selections=[\"degree\", \"pagerank\", \"random\"],\n",
    "                    ratios=[0.4, 0.4, 0.2],\n",
    "                    num_anchors=500,\n",
    "                ),\n",
    "                searcher=\"ScipySparse\",\n",
    "            ),\n",
    "            dict(),  # empty dict for the RelationTokenizer - it doesn't need any kwargs\n",
    "        ],\n",
    "        embedding_dim=1024,\n",
    "        interaction=\"distmult\",\n",
    "        relation_initializer=\"init_phases\",\n",
    "        relation_constrainer=\"complex_normalize\",\n",
    "        entity_initializer=\"xavier_uniform_\",\n",
    "        aggregation=DeepSet(hidden_dim=1024),\n",
    ")\n",
    "\n",
    "# Pick an optimizer from Torch\n",
    "from torch.optim import Adam\n",
    "optimizer = Adam(params=own_NodePiece.get_grad_params())\n",
    "\n",
    "# Pick a training approach that was imported !! contains the losses, choose between SLCWATrainingLoop and LCWATrainingLoop\n",
    "training_loop = SLCWATrainingLoop(    \n",
    "    model=own_NodePiece,\n",
    "    triples_factory=dataset.training,\n",
    "    optimizer=optimizer,\n",
    "    automatic_memory_optimization=True, \n",
    ")\n",
    "\n",
    "losses = training_loop.train(\n",
    "    \n",
    "    triples_factory=dataset.training,\n",
    "    num_epochs=4,\n",
    "    batch_size=None, #256, # if None -> automatic search for the best and greatest\n",
    "    checkpoint_name= \"First_33NodePiece\", # for example TransE_t2.pt\n",
    "    checkpoint_frequency=0,\n",
    "    checkpoint_directory='/sc-scratch/sc-scratch-ukb-cvd/checkpoints_pykeen_leonard', # new checkpoint dir bc of massive storage needs\n",
    "    \n",
    "    sub_batch_size=None, # not for SLCWA and not supported bc of batch normalization!!\n",
    "    slice_size=None, # not for SLCWA\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "result = pipeline(\n",
    "    dataset=own_tf,\n",
    "    model=NodePiece,\n",
    "    model_kwargs=dict(\n",
    "        tokenizers=[\"AnchorTokenizer\", \"RelationTokenizer\"],\n",
    "        num_tokens=[20, 12],\n",
    "        tokenizers_kwargs=[\n",
    "            dict(\n",
    "                selection=\"MixtureAnchorSelection\",\n",
    "                selection_kwargs=dict(\n",
    "                    selections=[\"degree\", \"pagerank\", \"random\"],\n",
    "                    ratios=[0.4, 0.4, 0.2],\n",
    "                    num_anchors=500,\n",
    "                ),\n",
    "                searcher=\"ScipySparse\",\n",
    "            ),\n",
    "            dict(),  # empty dict for the RelationTokenizer - it doesn't need any kwargs\n",
    "        ],\n",
    "        embedding_dim=64,\n",
    "        interaction=\"rotate\",\n",
    "        relation_initializer=\"init_phases\",\n",
    "        relation_constrainer=\"complex_normalize\",\n",
    "        entity_initializer=\"xavier_uniform_\",\n",
    "        aggregation=DeepSet(hidden_dim=64),\n",
    "    ),\n",
    ")\n",
    "result.plot()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e80864c-d149-4717-9934-35e93daa77cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "NodePiece(\n",
      "  (loss): MarginRankingLoss(\n",
      "    (margin_activation): ReLU()\n",
      "  )\n",
      "  (interaction): RotatEInteraction()\n",
      "  (entity_representations): ModuleList(\n",
      "    (0): NodePieceRepresentation(\n",
      "      aggregation=DeepSet(\n",
      "        (encoder): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (decoder): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "      ), \n",
      "      (token_representations): ModuleList(\n",
      "        (0): TokenizationRepresentation(\n",
      "          max_id=14505,\n",
      "          num_tokens=20,\n",
      "          vocabulary_size=501,\n",
      "          (vocabulary): Embedding(\n",
      "            (_embeddings): Embedding(501, 64)\n",
      "          )\n",
      "        )\n",
      "        (1): TokenizationRepresentation(\n",
      "          max_id=14505,\n",
      "          num_tokens=12,\n",
      "          vocabulary_size=475,\n",
      "          (vocabulary): Embedding(\n",
      "            (_embeddings): Embedding(475, 64)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (aggregation): DeepSet(\n",
      "        (encoder): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (decoder): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relation_representations): ModuleList(\n",
      "    (0): SubsetRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(475, 64)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (weight_regularizers): ModuleList()\n",
      ")\n",
      "torch.Size([14505, 64])\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.tensor([1.]) # dimension \n",
    "print(tensor)\n",
    "trainedM =own_NodePiece\n",
    "print(trainedM)\n",
    "moduleList=trainedM.entity_representations\n",
    "#print(moduleList[0])\n",
    "NodePieceRepresentation = moduleList[0]\n",
    "x =NodePieceRepresentation._plain_forward()\n",
    "print(x.size())\n",
    "#print(NodePieceRepresentation.aggregation.forward(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d82ce-a5ba-46c3-8ae7-465f7c74ec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
